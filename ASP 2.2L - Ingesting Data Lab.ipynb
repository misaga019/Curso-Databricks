{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e22dc6f-dea3-47c3-9868-4bc10af49d88"}}},{"cell_type":"markdown","source":["# Ingesting Data Lab\n\nRead in CSV files containing products data.\n\n##### Tasks\n1. Read with infer schema\n2. Read with user-defined schema\n3. Read with schema as DDL formatted string\n4. Write using Delta format"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5422c157-c034-445a-934d-c351529f27d5"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb947950-ddae-497e-bf23-102e198095b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nPython interpreter will be restarted.\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\nValidating the locally installed datasets...(3 seconds)\n\nPredefined tables in \"da_mikel_salgado_6634_asp\":\n  -none-\n\nPredefined paths variables:\n  DA.paths.user_db:     dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks/database.db\n  DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n  DA.paths.working_dir: dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks\n  DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks/_checkpoints\n  DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n  DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n  DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n  DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed in 4 seconds\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\nSkipping install of existing datasets to \"dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\"\n\nValidating the locally installed datasets...(3 seconds)\n\nPredefined tables in \"da_mikel_salgado_6634_asp\":\n  -none-\n\nPredefined paths variables:\n  DA.paths.user_db:     dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks/database.db\n  DA.paths.datasets:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03\n  DA.paths.working_dir: dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks\n  DA.paths.checkpoints: dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks/_checkpoints\n  DA.paths.sales:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/sales/sales.delta\n  DA.paths.users:       dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/users/users.delta\n  DA.paths.events:      dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/ecommerce/events/events.delta\n  DA.paths.products:    dbfs:/mnt/dbacademy-datasets/apache-spark-programming-with-databricks/v03/products/products.delta\n\nSetup completed in 4 seconds\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1. Read with infer schema\n- View the first CSV file using DBUtils method **`fs.head`** with the filepath provided in the variable **`single_product_cs_file_path`**\n- Create **`products_df`** by reading from CSV files located in the filepath provided in the variable **`products_csv_path`**\n  - Configure options to use first line as header and infer schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"22bdfc5d-e8ed-4285-b81b-d9fbac9cff93"}}},{"cell_type":"code","source":["# TODO\nsingle_product_csv_file_path = f\"{DA.paths.datasets}/products/products.csv/part-00000-tid-1663954264736839188-daf30e86-5967-4173-b9ae-d1481d3506db-2367-1-c000.csv\"\nprint(dbutils.fs.head(single_product_csv_file_path))\n\nproducts_csv_path = f\"{DA.paths.datasets}/products/products.csv\"\nproducts_df = (spark\n               .read\n               .option(\"header\", True)\n               .option(\"inferSchema\", True)\n               .csv(products_csv_path)\n)\n\nproducts_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"805b589a-7ec8-447f-abb3-2f763ec24019"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"item_id,name,price\nM_PREM_Q,Premium Queen Mattress,1795.0\nM_STAN_F,Standard Full Mattress,945.0\nM_PREM_F,Premium Full Mattress,1695.0\n\nroot\n |-- item_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["item_id,name,price\nM_PREM_Q,Premium Queen Mattress,1795.0\nM_STAN_F,Standard Full Mattress,945.0\nM_PREM_F,Premium Full Mattress,1695.0\n\nroot\n |-- item_id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- price: double (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["**1.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"48c79d19-6a5c-4e13-895f-f0ca7e46b6cc"}}},{"cell_type":"code","source":["assert(products_df.count() == 12)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"079d37b7-e732-496f-9b1c-805273f65616"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 2. Read with user-defined schema\nDefine schema by creating a **`StructType`** with column names and data types"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77f3a78a-4931-4ccb-8471-924e7284b16b"}}},{"cell_type":"code","source":["from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n\nuser_defined_schema = StructType([\n    StructField(\"item_id\", StringType(), True),\n    StructField(\"name\", StringType(), True),\n    StructField(\"price\", DoubleType(), True),\n])\n\nproducts_df2 = (spark\n                .read\n                .option(\"header\", True)\n                .schema(user_defined_schema)\n                .csv(products_csv_path)\n    \n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"abcae4fc-77b3-4ccd-bcaa-3ce76fce76b4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**2.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24086934-abd2-4b7f-a59b-91899af41968"}}},{"cell_type":"code","source":["assert(user_defined_schema.fieldNames() == [\"item_id\", \"name\", \"price\"])\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"418154f8-1871-4717-82aa-97915f1ca2e5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Row\n\nexpected1 = Row(item_id=\"M_STAN_Q\", name=\"Standard Queen Mattress\", price=1045.0)\nresult1 = products_df2.first()\n\nassert(expected1 == result1)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"37b07568-6e85-4db9-9d8d-e81c850a1f7a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3. Read with DDL formatted string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90be2a88-5d03-4051-9942-efebda7a23f9"}}},{"cell_type":"code","source":["# TODO\nddl_schema = \"`item_id` STRING,`name` STRING,`price` DOUBLE\"\n\nproducts_df3 = (spark\n                .read\n                .option(\"header\", True)\n                .schema(ddl_schema)\n                .csv(products_csv_path)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5f0b2a11-98d7-4c74-ad02-58f855764cfe"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**3.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c7ca5e2-068b-43f3-ba55-600b99040e0b"}}},{"cell_type":"code","source":["assert(products_df3.count() == 12)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffac7464-47cb-478a-b1ba-169f294883e0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-1978527400243151>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32massert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproducts_df3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m12\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"All test pass\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrameReader' object has no attribute 'count'","errorSummary":"<span class='ansi-red-fg'>AttributeError</span>: 'DataFrameReader' object has no attribute 'count'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-1978527400243151>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32massert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproducts_df3\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m12\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"All test pass\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrameReader' object has no attribute 'count'"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 4. Write to Delta\nWrite **`products_df`** to the filepath provided in the variable **`products_output_path`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24d67173-b173-4876-afa5-f8a2e30b2ee2"}}},{"cell_type":"code","source":["# TODO\nproducts_output_path = f\"{DA.paths.working_dir}/delta/products\"\n(products_df\n.write\n.format(\"delta\")\n.mode(\"overwrite\")\n.save(products_output_path)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e7f1a73-699f-4a67-b7c8-686e56788d9d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**4.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf11c584-cf51-45a9-9f9a-0c4a7498794b"}}},{"cell_type":"code","source":["verify_files = dbutils.fs.ls(products_output_path)\nverify_delta_format = False\nverify_num_data_files = 0\nfor f in verify_files:\n    if f.name == \"_delta_log/\":\n        verify_delta_format = True\n    elif f.name.endswith(\".parquet\"):\n        verify_num_data_files += 1\n\nassert verify_delta_format, \"Data not written in Delta format\"\nassert verify_num_data_files > 0, \"No data written\"\ndel verify_files, verify_delta_format, verify_num_data_files\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4bccdab-8363-4ffb-911c-c28e4983c3d3"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5086569f-9f29-442a-87a3-b0953ed5f067"}}},{"cell_type":"code","source":["DA.cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a780bd5-f73f-4903-b301-2ec696623a59"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Resetting the learning environment...\n...dropping the database \"da_mikel_salgado_6634_asp\"...(1 seconds)\n...removing the working directory \"dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks\"...(0 seconds)\n\nValidating the locally installed datasets...(4 seconds)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Resetting the learning environment...\n...dropping the database \"da_mikel_salgado_6634_asp\"...(1 seconds)\n...removing the working directory \"dbfs:/mnt/dbacademy-users/mikel.salgado@bosonit.com/apache-spark-programming-with-databricks\"...(0 seconds)\n\nValidating the locally installed datasets...(4 seconds)\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef229904-9684-41c3-a879-c46fcb8e3f29"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 2.2L - Ingesting Data Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1978527400243135}},"nbformat":4,"nbformat_minor":0}
